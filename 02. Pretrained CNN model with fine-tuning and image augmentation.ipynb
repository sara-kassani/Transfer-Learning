{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob \n",
    "import numpy as np \n",
    "import os \n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img \n",
    "np.random.seed(42) \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/training_data' \n",
    "val_dir = 'data/validation_data' \n",
    "test_dir = 'data/test_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (3000, 150, 150, 3) Validation dataset shape: (1000, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "IMG_DIM = (150, 150) \n",
    " \n",
    "train_files = glob.glob('data/training_data/*') \n",
    "train_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for img  \n",
    "              in train_files] \n",
    "train_imgs = np.array(train_imgs) \n",
    "train_labels = [fn.split('\\\\')[1].split('.')[0].strip() for fn in \n",
    "                train_files] \n",
    " \n",
    "validation_files = glob.glob('data/validation_data/*') \n",
    "validation_imgs = [img_to_array(load_img(img, target_size=IMG_DIM)) for \n",
    "                   img in validation_files] \n",
    "validation_imgs = np.array(validation_imgs) \n",
    "validation_labels = [fn.split('\\\\')[1].split('.')[0].strip() for fn in \n",
    "                     validation_files] \n",
    " \n",
    "print('Train dataset shape:', train_imgs.shape,  \n",
    "      'Validation dataset shape:', validation_imgs.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### basic configuration parameters and also encode our text class labels into numeric values (otherwise, Keras will throw an error):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat', 'cat', 'cat', 'cat', 'cat', 'dog', 'dog', 'dog', 'dog', 'dog'] [0 0 0 0 0 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 30 \n",
    "num_classes = 2 \n",
    "epochs = 30 \n",
    "input_shape = (150, 150, 3) \n",
    " \n",
    "# encode text category labels \n",
    "from sklearn.preprocessing import LabelEncoder \n",
    " \n",
    "le = LabelEncoder() \n",
    "le.fit(train_labels) \n",
    "train_labels_enc = le.transform(train_labels) \n",
    "validation_labels_enc = le.transform(validation_labels) \n",
    " \n",
    "print(train_labels[1495:1505], train_labels_enc[1495:1505]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generators \n",
    "train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.3,                  \n",
    "                                   rotation_range=50, \n",
    "                                   width_shift_range=0.2,  \n",
    "                                   height_shift_range=0.2,    \n",
    "                                   shear_range=0.2,  \n",
    "                                   horizontal_flip=True, \n",
    "                                   fill_mode='nearest') \n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255) \n",
    "\n",
    "train_generator = train_datagen.flow(train_imgs, train_labels_enc,  \n",
    "                                     batch_size=30) \n",
    "val_generator = val_datagen.flow(validation_imgs, \n",
    "                                 validation_labels_enc, \n",
    "                                 batch_size=20) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretrained models are used in the following two popular ways when building new models or reusing them:\n",
    "\n",
    "    Using a pretrained model as a feature extractor\n",
    "    Fine-tuning the pretrained model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained CNN model with fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will now leverage our VGG-16 model object stored in the vgg_model variable and unfreeze convolution blocks 4 and 5 while keeping the first three blocks frozen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import vgg16 \n",
    "from keras.models import Model \n",
    "import keras \n",
    "\n",
    "\n",
    "vgg = vgg16.VGG16(include_top=False, weights='imagenet',  \n",
    "                                     input_shape=input_shape) \n",
    "\n",
    "# we have removed the final part of the classifier pertaining to the VGG-16 model \n",
    "#since we will be building our own classifier and leveraging VGG as a feature extractor\n",
    "output = vgg.layers[-1].output \n",
    "output = keras.layers.Flatten()(output) \n",
    "vgg_model = Model(vgg.input, output) \n",
    "\n",
    " \n",
    "vgg_model.trainable = True \n",
    "set_trainable = False\n",
    " \n",
    "for layer in vgg_model.layers: \n",
    "    if layer.name in ['block5_conv1', 'block4_conv1']: \n",
    "        set_trainable = True \n",
    "    if set_trainable: \n",
    "        layer.trainable = True \n",
    "    else: \n",
    "        layer.trainable = False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can clearly see from the preceding output that the convolution and pooling layers pertaining to blocks 4 and 5 are now trainable, and you can also verify which layers are frozen and unfrozen using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer Type</th>\n",
       "      <th>Layer Name</th>\n",
       "      <th>Layer Trainable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;keras.engine.input_layer.InputLayer object at 0x000002750A819AC8&gt;</td>\n",
       "      <td>input_1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x000002750A819E48&gt;</td>\n",
       "      <td>block1_conv1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x000002750A822160&gt;</td>\n",
       "      <td>block1_conv2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;keras.layers.pooling.MaxPooling2D object at 0x000002750A84B588&gt;</td>\n",
       "      <td>block1_pool</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x000002750A84BA90&gt;</td>\n",
       "      <td>block2_conv1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x000002750A86B860&gt;</td>\n",
       "      <td>block2_conv2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;keras.layers.pooling.MaxPooling2D object at 0x000002750A885550&gt;</td>\n",
       "      <td>block2_pool</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x000002750A885F98&gt;</td>\n",
       "      <td>block3_conv1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x000002750A8BC978&gt;</td>\n",
       "      <td>block3_conv2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x000002750A8DAB38&gt;</td>\n",
       "      <td>block3_conv3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;keras.layers.pooling.MaxPooling2D object at 0x000002750A8ED5C0&gt;</td>\n",
       "      <td>block3_pool</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x000002750A8ED828&gt;</td>\n",
       "      <td>block4_conv1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x000002750A92BEB8&gt;</td>\n",
       "      <td>block4_conv2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x000002750A946B38&gt;</td>\n",
       "      <td>block4_conv3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>&lt;keras.layers.pooling.MaxPooling2D object at 0x000002750A95C5C0&gt;</td>\n",
       "      <td>block4_pool</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x000002750A95C828&gt;</td>\n",
       "      <td>block5_conv1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x000002750A997EB8&gt;</td>\n",
       "      <td>block5_conv2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>&lt;keras.layers.convolutional.Conv2D object at 0x000002750A9B3B38&gt;</td>\n",
       "      <td>block5_conv3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>&lt;keras.layers.pooling.MaxPooling2D object at 0x000002750A9C95C0&gt;</td>\n",
       "      <td>block5_pool</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&lt;keras.layers.core.Flatten object at 0x000002750A9EA780&gt;</td>\n",
       "      <td>flatten_1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            Layer Type  \\\n",
       "0   <keras.engine.input_layer.InputLayer object at 0x000002750A819AC8>   \n",
       "1   <keras.layers.convolutional.Conv2D object at 0x000002750A819E48>     \n",
       "2   <keras.layers.convolutional.Conv2D object at 0x000002750A822160>     \n",
       "3   <keras.layers.pooling.MaxPooling2D object at 0x000002750A84B588>     \n",
       "4   <keras.layers.convolutional.Conv2D object at 0x000002750A84BA90>     \n",
       "5   <keras.layers.convolutional.Conv2D object at 0x000002750A86B860>     \n",
       "6   <keras.layers.pooling.MaxPooling2D object at 0x000002750A885550>     \n",
       "7   <keras.layers.convolutional.Conv2D object at 0x000002750A885F98>     \n",
       "8   <keras.layers.convolutional.Conv2D object at 0x000002750A8BC978>     \n",
       "9   <keras.layers.convolutional.Conv2D object at 0x000002750A8DAB38>     \n",
       "10  <keras.layers.pooling.MaxPooling2D object at 0x000002750A8ED5C0>     \n",
       "11  <keras.layers.convolutional.Conv2D object at 0x000002750A8ED828>     \n",
       "12  <keras.layers.convolutional.Conv2D object at 0x000002750A92BEB8>     \n",
       "13  <keras.layers.convolutional.Conv2D object at 0x000002750A946B38>     \n",
       "14  <keras.layers.pooling.MaxPooling2D object at 0x000002750A95C5C0>     \n",
       "15  <keras.layers.convolutional.Conv2D object at 0x000002750A95C828>     \n",
       "16  <keras.layers.convolutional.Conv2D object at 0x000002750A997EB8>     \n",
       "17  <keras.layers.convolutional.Conv2D object at 0x000002750A9B3B38>     \n",
       "18  <keras.layers.pooling.MaxPooling2D object at 0x000002750A9C95C0>     \n",
       "19  <keras.layers.core.Flatten object at 0x000002750A9EA780>             \n",
       "\n",
       "      Layer Name  Layer Trainable  \n",
       "0   input_1       False            \n",
       "1   block1_conv1  False            \n",
       "2   block1_conv2  False            \n",
       "3   block1_pool   False            \n",
       "4   block2_conv1  False            \n",
       "5   block2_conv2  False            \n",
       "6   block2_pool   False            \n",
       "7   block3_conv1  False            \n",
       "8   block3_conv2  False            \n",
       "9   block3_conv3  False            \n",
       "10  block3_pool   False            \n",
       "11  block4_conv1  True             \n",
       "12  block4_conv2  True             \n",
       "13  block4_conv3  True             \n",
       "14  block4_pool   True             \n",
       "15  block5_conv1  True             \n",
       "16  block5_conv2  True             \n",
       "17  block5_conv3  True             \n",
       "18  block5_pool   True             \n",
       "19  flatten_1     True             "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "pd.set_option('max_colwidth', -1)\n",
    "\n",
    "layers = [(layer, layer.name, layer.trainable) for layer in vgg_model.layers] \n",
    "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can clearly see that the last two blocks are now trainable, which means the weights for these layers will also get updated with backpropagation in each epoch as we pass each batch of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable layers: [<tf.Variable 'block4_conv1_1/kernel:0' shape=(3, 3, 256, 512) dtype=float32_ref>, <tf.Variable 'block4_conv1_1/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'block4_conv2_1/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'block4_conv2_1/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'block4_conv3_1/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'block4_conv3_1/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'block5_conv1_1/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'block5_conv1_1/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'block5_conv2_1/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'block5_conv2_1/bias:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'block5_conv3_1/kernel:0' shape=(3, 3, 512, 512) dtype=float32_ref>, <tf.Variable 'block5_conv3_1/bias:0' shape=(512,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "print(\"Trainable layers:\", vgg_model.trainable_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We reduce the learning rate slightly since we don't want to get stuck at any local minimal, and we also do not want to suddenly update the weights of the trainable VGG-16 model layers by a big factor that might adversely affect the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer \n",
    "from keras.models import Sequential \n",
    "from keras import optimizers \n",
    "\n",
    "# build model architecture \n",
    "model = Sequential() \n",
    "\n",
    "model.add(vgg_model) \n",
    "model.add(Dense(512, activation='relu', input_dim=input_shape)) \n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(512, activation='relu')) \n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.RMSprop(lr=1e-5), \n",
    "              metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "100/100 [==============================] - 1243s 12s/step - loss: 0.5797 - acc: 0.6877 - val_loss: 0.3201 - val_acc: 0.8620\n",
      "Epoch 2/2\n",
      " 99/100 [============================>.] - ETA: 10s - loss: 0.4028 - acc: 0.8286"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator, steps_per_epoch=100, \n",
    "                              epochs=2,  \n",
    "                              validation_data=val_generator,   \n",
    "                              validation_steps=50,  \n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cats_dogs_tlearn_finetune_img_aug_cnn.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
